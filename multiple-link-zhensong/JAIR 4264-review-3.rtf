{\rtf1\ansi\ansicpg1252\deff0\deflang1033{\fonttbl{\f0\fnil\fcharset0 Calibri;}}
{\*\generator Msftedit 5.41.21.2510;}\viewkind4\uc1\pard\sa200\sl276\slmult1\lang9\f0\fs22\par
This paper presents a class-level probability semantics for parameterized Bayes nets. Under this semantics, a parameterized BN represents the joint distribution induced by sampling values for the logical variables independently from their populations and then evaluating the parameterized nodes on the sampled individuals. The paper also presents a relational log-linear inference model for Bayes nets. Specifically, it shows a novel relational inference method for relational models with cyclic dependencies. The key idea  is to define the log-probability of a target node value as the expected log-probability for a random instantiation of the node's Markov blanket. The key innovation is the use of frequencies of the instances as against the counts that are normally used in probabilistic modeling. The authors claim to make two key contributions (1) To compute conditional probabilities using local neighborhood instead of the full Bayes net and (2) A new log linear equation that uses conditional frequencies as against fractional counts for estimation of probabilities.\par
Relational inference is an important problem and there is a lot of focus on this problem. There is a lot of thrust in this problem and subsequently has yielded a new research area that has captivated the attention of the probabilistic logic community. From this perspective, this paper addresses a very important problem. Cyclic dependencies are the major hurdle in development of these relational inference methods with directed models since they do not result in a Bayesian network thus making it impossible to perform inference in the underlying network. This has forced the use of undirected models for inference in most relational tasks. This paper, on the other hand proposes a novel inference approach that essentially treats the log-probability of a target node value as the expected  log-probability for a random instantiation of the node's Markov blanket. From this perspective, this paper makes an important contribution as that of the other methods based on dependency networks that simplify the model to perform more efficient inference. This paper reinforces the claim that sometimes these approximations are powerful enough to perform efficient yet effective inference.\par
In addition, the use of frequencies instead of counts seems a simple yet quite novel and interesting idea. The estimation of sufficient statistics across the entire data set allows one to answer queries more efficiently. Other than the contributions stated above (in the paper), this to me is the main contribution of the paper and possibly the most important one as well. \par
While the items listed above are good contributions, the paper has some serious flaws that need attention.\par
* First the organization of the paper must be improved drastically. From how it is being presented, it is not clear what the contributions are and how the paper is different from the other ones that the authors have published earlier. So I would suggest a complete reorganization that first motivates the problem clearly then shows what the prior work in the area by the authors are and next presents the current proposed algorithm.Identify the issues with the prior work, then show clearly the experimental contributions. The paper currently reads in a haphazard manner. \par
* A bigger problem for me is that the paper seems to be reinventing the wheels and keeps defining new terms. To me this suggests lack of acknowledgement to relevant work (which of course appear in a section later). I do not see the need for the definition of new terms. The notion of Gibbs conditional probabilities is simply pseudo-likelihood estimated using Gibbs sampling. This has been done so many times in the literature as the authors point out by the work of Heckerman, then Neville and later by Natarajan's group. In this case, there is no necessity to define the Gibbs conditional probabilities. \par
* Same argument applies to the use of template bayes nets. Why introduce a new terminology into an already existing alphabetical soup. There are way too many SRL models out there and I do not see the need for introducing a new one. This seems to deliberately introduce an unnecessarily new formalism. \par
* The claim that viewing the probability locally is a new contribution is also quite far fetched. As I mentioned earlier, this has been done so many times in the dependency network literature which the authors have quite diligently cited. So it is not the case that the authors are unaware of this line work. They have given due credit to the body of literature. Why then claim viewing the joint distribution locally as a new contribution? As I mentioned earlier, the key contribution is the use of frequencies and not counts. Using them in the context of local distributions is the contribution and not using only the local distribution to infer for a single variable. These types of claims make the most important and interesting claim of the paper look shallow. I suggest that the authors take a deep look at the claims and rewrite the paper to put the current work in correct context to the rest of the existing body of literature in SRL.\par
* From what they are describing, the relevant and irrelevant groundings simply seem to the ones that were called as trivial groundings and non-trivial groundings in literature (for instance, the work of Shavlik (2009) and data base systems like Tuffy). This connection must be made clear and if these are essentially non-trivial groundings then there is no necessity to give this a new name and definition as the authors have done here.\par
* What they are doing is essentially an RDN where they employ frequencies instead of counts. Why mask it as a new formalism when it can be presented directly this way?\par
 * This leads me to question the experiments. Their big claim is that this is scalable and accurate. Let me address scalability first. They claim that the work on functional gradient boosting cannot scale to large data sets. When I checked Natarajan et al (2012), they seem to have applied this algorithm to most of the data sets that are presented here and a few more. So why have the authors not compared to any of their literature? Where is the back up to the claim that the other work cannot scale? This must be proved if the authors want to show better performance.\par
* Similarly w.r.t accuracy, I checked the paper by Khot et al.(2011) and their performance in CLL for UW is better or equal to the proposed approach here. Why is then the claim about better and scale valid? Why did they not compare against any of these methods.\par
\par
* I find the scale argument particularly weak. This is due to the fact that Tuffy (Niu 2012) have dealt with millions of documents and used Gibbs sampling to perform efficient inference. This work completely ignores this related system that is publicly available for download. Should you not back up your claim by comparing against this system. The number of ground instances used in this paper are far less than the web-scale KBC that they use in their system.\par
* I do not see the point of using only accuracy. We know that it is not a valid measure -- particularly in relational domains where the number of negatives far outweigh the positives. In this case, simply using CLL or accuracy can be misleading. You can consider one vs all and calculate the operating points for each class and then average the AUC. But more pertinently, in UW and movie lens, the prediction is still binary. Why not compare the AUC in these domains and present the results? This will help us compare against the current methods.\par
* Having a  statement that Alchemy weight optimization is 10 hours is not sufficient. To prove scientifically, they should compare against other systems and learning algorithms. \par
* Finally, I am not even sure if the hype is correct. They talk of efficient learning and optimization. But these are not shown in the context of an entire bayes net. They simply learn and predict for one target variable which is essentially a relational classification problem. There are several baselines possible for this task.\par
* Some of the citations are not in place and not correct. Why have a self-cite when talking about counts? And other citations are out of place. \par
Over all, I feel that the paper has quite a bit of promise when focussed only on the key contributions. But it is distracting to see other new definitions and terms that are defined earlier in literature. Then the claims are not validated. The experiments need to be significantly improved for the paper to be accepted by adding more baselines.\par
}
 