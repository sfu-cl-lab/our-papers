{\rtf1\ansi\ansicpg1252\cocoartf1138\cocoasubrtf510
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;\red108\green108\blue108;\red0\green0\blue0;}
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural

\f0\b\fs36 \cf2 From: 
\b0 \cf3 AAAI-14 <aaai14@easychair.org>\

\b \cf2 Subject: 
\b0 \cf3 new review for AAAI-14 paper 1079\

\b \cf2 Date: 
\b0 \cf3 18 March, 2014 14:13:08 PDT\

\b \cf2 To: 
\b0 \cf3 Oliver Schulte <oschulte@cs.sfu.ca>\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural

\fs24 \cf3 \
\pard\pardeftab720

\fs32 \cf3 ----------------------- REVIEW 3 ---------------------\
PAPER: 1079\
TITLE: SFNET: Streaming Feature Selection for Dynamic Drifting Networks\
AUTHORS: (anonymous)\
\
PC MEMBER: Jen Neville\
REVIEWER: Joseph Pfeiffer\
1. Technical Quality: 4 (positive, a factor in accepting the paper)\
2. Experimental analysis: 1 (flawed, a sufficient basis to reject the paper)\
3. Formal analysis: 3 (adequate, not a basis for accepting or rejecting the paper)\
4. Clarity/presentation: 2 (problematic, a factor in rejecting the paper)\
5. Novelty/innovation of question addressed: 4 (positive, a factor in accepting the paper)\
6. Novelty/innovation of application: 4 (positive, a factor in accepting the paper)\
7. Novelty/innovation with respect to aspects of human-level \'a0\'a0intelligence, complex cognition, or similar topics (Cognitive \'a0Systems): 3 (adequate, not a basis for accepting or rejecting the paper (or not applicable))\
8. Novelty/innovation of solution proposed: 4 (positive, a factor in accepting the paper)\
9. Breadth of interest to the AI community: 4 (positive, a factor in accepting the paper)\
10. Potential for impact to practical applications: 3 (adequate, not a basis for accepting or rejecting the paper (or not applicable))\
SUMMARY RATING: -1 (Weak rejection. No 1, 5 or 6 in any category, overall 3 or below.)\
REVIEWER'S CONFIDENCE: 2 (I am somewhat certain of my scores)\
\
----------- QUALITY JUSTIFICATION -----------\
Overall the work is well written, with only minor grammatical typos. However, some of the notations could use some clarification. \'a0A primary concern is with regards to bolding and indexing vectors and matrices. \'a0For example, in Eq. 1 f_i^r is used to index a scalar but is bolded, while J(f) is not bolded when it is a vector. \'a0This contrasts with usual notation and makes the paper considerably harder to read. \'a0Further, at times the matrix notation is A_ij (which makes sense), but other times A_i^k is used (definition of \\theta^k) which can confuse the reader. \'a0The link similarity objective function is never discussed.\
\
The experimental analysis is flawed. \'a0First, text classification almost always length normalizes the vector (particularly when label distributions are skewed [1]); this step is not done for either dataset. \'a0After the vectors are length normalized, comparison without feature selection should be done as a baseline as this usually performs well. \'a0Second, it is unclear why a subset of nodes is chosen from DBLP and PubMed; the algorithm presented should have fast updates, so it seems that the entire network should be used. \'a0Figure 6 might indicate the competitors cannot keep up; omitting them for a large network example is acceptable when coupled with this figure. \'a0Third, Information Gain is not tested on the dynamic networks \'97 it should easily keep up in the larger network analysis.\
\
[1] Forman. \'a0An extensive empirical study of feature selection metrics for text classification.\
\
----------- NOVELTY/INNOVATION JUSTIFICATION -----------\
The solution is innovative, and having fast updates is useful in practice for many dynamic networks.\
\
----------- IMPACT JUSTIFICATION -----------\
Feature selection is an ongoing area of research, and tying in relational domains (which many text classification algorithms fall into) is of interest to the community.\
\
----------- SUMMARY OF REVIEW FOR AUTHORS -----------\
This paper discusses a novel method for doing feature selection in dynamic network domains. \'a0The solution allows for dynamic updates, omitting the need to recompute over all features at each time step. \'a0However, the empirical evaluation is performed on relatively small datasets despite the scalable claims and does not consistently compare against state of the art baselines (length normalized text vectors w/o feature selection).\
\
----------- CONFIDENTIAL REMARKS FOR THE PROGRAM COMMITTEE -----------\
(missing)\
}