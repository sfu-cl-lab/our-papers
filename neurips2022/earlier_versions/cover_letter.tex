%File: anonymous-submission-latex-2023.tex
\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage[submission]{aaai23}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in} % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in} % DO NOT CHANGE THIS
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb,amsfonts}
\usepackage{booktabs}
\usepackage{subcaption}
\usepackage{enumitem}
\usepackage{pifont}
\usepackage{mathtools}
\usepackage{arydshln}
\usepackage{multirow}
%
% These are recommended to typeset algorithms but not required. See the subsubsection on algorithms. Remove them if you don't have algorithms in your paper.
\usepackage{algorithm}
\usepackage{algorithmic}

%
% These are are recommended to typeset listings but not required. See the subsubsection on listing. Remove this block if you don't have listings in your paper.
\usepackage{newfloat}
\usepackage{listings}
\usepackage{color}

\newcommand{\modelParamter}{\omega}
\newcommand{\horizon}{T_{H}}
\newcommand{\datapoint}{x}
\newcommand{\condition}{\boldsymbol{z}_{E}}
\newcommand{\state}{s}
\newcommand{\observation}{o}
\newcommand{\action}{a}
\newcommand{\transition}{t}
\newcommand{\reward}{r}
\newcommand{\agentIndex}{k}
\newcommand{\gameIndex}{j}
\newcommand{\quantielIndex}{i}
\newcommand{\dataset}{\mathcal{D}}
\newcommand{\expect}{\mathbb{E}}
\newcommand{\feature}{e}
\newcommand{\confidence}{c}
\newcommand{\error}{\epsilon}
\newcommand{\impact}{\phi}
\newcommand{\playerId}{l}
\newcommand{\constant}{C}
\newcommand{\splitnum}{m}
\newcommand{\sys}{RiGIM}
\newcommand{\bin}{B}
\newcommand{\goal}{g}
\newcommand{\system}{\sys\;}
\newtheorem{example}{Example}
\newtheorem{proposition}{Proposition}
\DeclareMathOperator*{\argmax}{argmax}

\DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} % DO NOT CHANGE THIS
\lstset{%
	basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
	numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
	aboveskip=0pt,belowskip=0pt,%
	showstringspaces=false,tabsize=2,breaklines=true}
\floatstyle{ruled}
\newfloat{listing}{tb}{lst}{}
\floatname{listing}{Listing}
%
% Keep the \pdfinfo as shown here. There's no need
% for you to add the /Title and /Author tags.
\pdfinfo{
/TemplateVersion (2023.1)
}

% DISALLOWED PACKAGES
% \usepackage{authblk} -- This package is specifically forbidden
% \usepackage{balance} -- This package is specifically forbidden
% \usepackage{color (if used in text)
% \usepackage{CJK} -- This package is specifically forbidden
% \usepackage{float} -- This package is specifically forbidden
% \usepackage{flushend} -- This package is specifically forbidden
% \usepackage{fontenc} -- This package is specifically forbidden
% \usepackage{fullpage} -- This package is specifically forbidden
% \usepackage{geometry} -- This package is specifically forbidden
% \usepackage{grffile} -- This package is specifically forbidden
% \usepackage{hyperref} -- This package is specifically forbidden
% \usepackage{navigator} -- This package is specifically forbidden
% (or any other package that embeds links such as navigator or hyperref)
% \indentfirst} -- This package is specifically forbidden
% \layout} -- This package is specifically forbidden
% \multicol} -- This package is specifically forbidden
% \nameref} -- This package is specifically forbidden
% \usepackage{savetrees} -- This package is specifically forbidden
% \usepackage{setspace} -- This package is specifically forbidden
% \usepackage{stfloats} -- This package is specifically forbidden
% \usepackage{tabu} -- This package is specifically forbidden
% \usepackage{titlesec} -- This package is specifically forbidden
% \usepackage{tocbibind} -- This package is specifically forbidden
% \usepackage{ulem} -- This package is specifically forbidden
% \usepackage{wrapfig} -- This package is specifically forbidden
% DISALLOWED COMMANDS
% \nocopyright -- Your paper will not be published if you use this command
% \addtolength -- This command may not be used
% \balance -- This command may not be used
% \baselinestretch -- Your paper will not be published if you use this command
% \clearpage -- No page breaks of any kind may be used for the final version of your paper
% \columnsep -- This command may not be used
% \newpage -- No page breaks of any kind may be used for the final version of your paper
% \pagebreak -- No page breaks of any kind may be used for the final version of your paperr
% \pagestyle -- This command may not be used
% \tiny -- This is not an acceptable font size.
% \vspace{- -- No negative value may be used in proximity of a caption, figure, table, section, subsection, subsubsection, or reference
% \vskip{- -- No negative value may be used to alter spacing above or below a caption, figure, table, section, subsection, subsubsection, or reference

\setcounter{secnumdepth}{0} %May be changed to 1 or 2 if section numbers are desired.

% The file aaai23.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%

% Title

% Your title must be in mixed case, not sentence case.
% That means all verbs (including short verbs like be, is, using,and go),
% nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while
% articles, conjunctions, and prepositions are lower case unless they
% directly follow a colon or long dash
\title{Cover Letter}

% REMOVE THIS: bibentry
% This is only needed to show inline citations in the guidelines document. You should not need it and can safely delete it.
\usepackage{bibentry}
% END REMOVE bibentry

\begin{document}


\maketitle

\author{}

\begin{abstract}
This cover letter provides details on our efforts to substantially improve the AAAI 2023 submission of the paper “Uncertainty-Aware Reinforcement Learning for Risk-Sensitive Player Evaluation in Sports Game” upon our previous Neurips 2022 submission. We addressed all major comments of the Neurips 2022 reviewers and in fact resolved every major issue raised by them. We also provide clarifications and justifications of all other points raised by the reviewers. we show a summary of our updates and include a response to points raised by reviewers,
\end{abstract}

\section{Summary of Updates}

To clarify our modifications and prevent misunderstanding, we summarize our major updates in the following:
\begin{itemize}
    \item {\bf Player Ranking.} We provide more explanations for the risk-sensitive ranking results (Check appendix C.2, including Table C.3, Table C.4 and Table C.5. We show the motivation of rankings under different confidence levels $c$ and a brief explanation of the results from perspective of action frequency.
    \item {\bf Correlation with Success Measures.} We add the motivations of applying the correlations with success measures to evaluate the player ranking metrics (see Section "Player Evaluation Performance"). We also expand the explanation of our experiment results according to the comments from our reviewers.
    \item {\bf Confidence level.} We show the motivation of applying $c$ as a hyper-parameters (see Section "Player Evaluation Performance") and briefly explain why we set $c$ to some specific values in different empirical studies. We explore the option of determining the risk level by utilizing the validation dataset. We add the results to Tables 1 and 2.
    \item {\bf Significance Test.} In order to show our results are significantly different from comparison methods, we add a Wilcoxon test to the experiment results in Section "Scoring Chance Prediction Performance".
    \item {\bf Action Distribution Visualizaton.} In order to resolve the concerns (why defensemen are risk averse) from reviewer kCNJ, we add visualizations of the predicted distributions of shots, carry and pass in Appendix C.3.
    \item {\bf Complexity Analysis.} As reviewer mdqR suggested, we introduce the computational complexity and model complexity in Appendix A.4.
    \item {\bf Analysis over the Scale of Uncertainty.} We study the scale of epistemic uncertainty as more games are observed and reported the results in Appendix C.4 according to the comments from reviewer mdqR.
\end{itemize}


Apart from the academic contributions in the paper, our risk-measuring method has {\it realistic contribution}: we presented our ideas to some experts from the sports industry. They agreed on the value of computing the risk of player movements and suggested ranking players or teams according to their risk. Their intuition is {\it stronger teams or players take more risks}. This intuition is consistent with our findings in the risk-sensitive experiment. Sports, as a sequential-decision game and an important part of the entertainment industry, often admires risk. On the other hand,  most RL algorithms (typically offline RL) prefer a {\it conservative policy} to handle risk and uncertainty. We believe this difference requires more study in the following work. 

\section{Addressing the Comments from Reviewer mdqR}

\begin{itemize}
    \item "{\it What does employing a risk-based cutoff add to the existing analyst techniques? Having a variety of cut-off thresholds (like all hyperparameters) makes assessment more complex, begging the question: what are the benefits for these additional complexity costs? The empirical results make one useful case about better calibration, but the text would benefit from clarifying the impact and significance to how analysts (or players or coaches) would use this new information.}"
    
    The cut-off, determined by confidence value $c$, is proposed to differentiate risk-seeking players from risk-averse ones. Following the designs of popular risk-measures like Conditional Value at Risk (CVaR), we treat $c$ as a hyper-parameter.  In practice, we allow the coaches or managers to pick a confidence value depending on whether they want to find the risk-seeking players (with a small $c$) or the risk-averse ones (with a large $c$). Figure 1 shows an example: if we set $c=0.8$, the action (a) will have larger values and the corresponding player could be assigned more credits. However, when we set $c=0.2$, the player who performs action (b) should be ranked higher, although these two actions (a and b) have the same expected value.
    \medskip
    
    \item "{\it What new insights can be obtained from the rankings provided? How are these of interest to those with domain expertise? Practitioners?}"
    
    Table C.3 shows a risk-averse ranking (with confidence 0.2) that favors offensive players (e.g., Centres (C)) with strong scoring ability. Table C.4 shows a risk-sensitive ranking that highlights players in defensive positions. We use Aleksander Barkov and John Klingberg as two examples. These tables illustrates how a domain expert could use our method to gain insight into which types of players exhibit different risk-taking behavior. Also Figures 4 and 5 indicate which action types are riskier. In practice, team and managers are encouraged to use our method for predictive estimation for players' performance.   
    \medskip
    
    \item "{\it How does RiGIM scale? and How does model training scale in terms of compute resources needed?}"
    
    We believe RiGIM can be easily extended to offline RL and other learning-from-demonstration applications given a trajectory dataset (Appendix A.1). In this work, since the input to the models are symbolic features (i.e., features with physical meaning like x-y coordinates and velocities), we simply use a fully-connected neural layer as feature extractor. However, if the data is in the format of images and text, stronger feature extractors will be required. We report the Computational Resources and Running Time in Appendix A.4.
    \medskip
    
    \item "{\it How much does the model improve as the number of matches observed increases?}"
    
    RiGIM is uncertainty-aware. Intuitively, increasing the number of training games reduces the scale of epistemic uncertainty, but the scale of aleatoric uncertainty will not decrease ((Mavrin et al. 2019)) explores this phenomenon), so our uncertainty-aware method should still out-perform risk-neural (or expectation-based) methods.
    \smallskip
    
    Borislav Mavrin, Hengshuai Yao, Linglong Kong, Kaiwen Wu, and Yaoliang Yu. Distributional reinforcement learning for efficient exploration. In International Conference on Machine Learning (ICML), volume 97, pages 4424–4434, 2019
    \medskip
    
    \item "{\it How effective is the model for evaluating new players (presumably since the player is not a feature of the model cold start problems should be lesser)?}"
    
    The inputs of our model are state-action pairs without including the identities of players. Thanks to the generalization ability of neural models, we can assign a proper value to the movements of unknown players if his or her playing style is similar to that of players in the training dataset.
    \medskip
    
    \item "{\it  (Table 1) Why might SI do so well at predicting Goals and Game Winning Goals compared to the alternatives? There is a substantial gap between the performance of SI and the runner up for Goals (0.596 vs 0.477) and GWG (0.409 vs 0.266). What is RiGIM failing to capture that SI does?}"
    
    Table 1 is for player evaluation instead of predicting goals. In other words, the model knows the scoring states (with reward 1)  during a game. The goal is not to predict whether a goal will be scored after performing an action in a state but to assign all the state-action pairs (mostly with reward 0) some proper credits. If the credits are correctly assigned, the corresponding metric should be well correlated with most of the well-known success measures.
    When it comes to SI, this is a model based on discretizing the continuous state features (time and space), then applying dynamic programming to a tabular state representation (See citation [1]).
    It correlates well with goal measures (Goals and Game Winning Goals) but has relatively poor correlations with other measures. This is because assigning an adequate value for {\em all} actions, including those with only intermediate effects on goal scoring, requires credit propagation over longer sequences (up to 13 steps). For continuous spatio-temporal processes like ice hockey, neural nets are better at credit propagation than discretizing and using a tabular representation.
    \medskip
    
    \item{\it "My question around scalability was intended to ask about the big-O scalability of runtime or memory of the algorithm. Or an empirical estimate of it such as running the model on 20\%, 40\%, 60\%, 80\%, 100\% of the data and assessing the runtime and GPU memory needs."}

    We apologize for our misunderstanding. We include an analysis of the computational complexity and memory complexity in appendix A.4.
    \medskip

   \item{\it "Is there any empirical validation of this for the model (even if only the full RiGIM model)? Practitioners would presumably want some validation that the model with more data will better support their decision-making through more accurate assessments. I believe the scaling explanation, but given the task (separating aleatory and epistemic uncertainty) is novel it would help to demonstrate this holds empirically."}

    We will add an experiment to validate our claim. The scale of epistemic uncertainty will reduce as more data are observed. In our work, epistemic uncertainty is measured by the feature-space density estimator. We will add an experiment to compute the scale of the density of a testing game as more games are observed during training. We will report the results and notify the reviewer as soon as our experiment is done. 
    \medskip
\end{itemize}

\section{Addressing the Comments from Reviewer kCNJ}
\begin{itemize}
    \item "{\it Can you give some intuitions for the case study results in Table 1/2. The only comment is that there are more defensemen in the higher confidence top 10 -- although this is true empirically -- why is this a prediction of higher confidence? It doesn't seem to clearly correlate with the other metrics shown. Tyler Seguin and Connor McDavid have similar stats and play in the same position so what accounts for them being in the different top 10 lists? The authors mention a couple of qualitative findings e.g., "low confidence favors centers, strong scoring ability) but its not clear what is driving these predictions. How would a layperson use this tool?}"
    
    Our paper shows that the risk-averse ranking includes more defensemen. This illustrates how a layperson could use our method to gain insight into which types of players exhibit different risk-taking behavior. Our intuitive explanation for this finding is that the riGIM risk metric is correlated with the action types a player performs. Intuitively, in ice-hockey, some actions are more risk-seeking (shot) in terms of scoring while other actions are risk-averse (carry or pass). In general, players on the backcourt (e.g., defensemen) are more likely to perform risk-averse actions that have smaller variance and are not directly related to shooting and scoring.
    In terms of the rankings for Tyler Seguin and Connor McDavid, stats are based only on goals and assists, whereas the RiGIM metric uses all the play-by-play data so it is context-aware and 
    takes into account much more information. So we would not expect RiGIM to always agree with the conventional stats. We provide the stats to provide some context for readers who may not be familiar with who these players are. Also it shows that our ranking passes the ``eye test" in that well-known stars that are big goal scores/contributors stand out.
    \medskip

    \item "{\it For tables 4/5/6, why was c set to 0.5 instead of fit on the validation set? How would one decide on a value for c in practice?}"
    
    This is because the comparison methods are expectation-based metrics. For a fair comparison, in section 6.1, we set $c$ to 0.5 for a risk-neutral version of RiGIM. The risk-sensitive results are shown in Section "Scoring Chance Prediction Performance". Setting $c$ to the value that maximizes the RiGIM correlations in the validation set could be an alternative approach. Intuitively, it will further improve the RiGIM performance, although the comparison could be a little biased. In practice, the coaches or managers should pick a confidence value depending on whether they want to find the risk-seeking players (with a small $c$) or the risk-averse ones (with a large $c$). This is similar to determining the confidence value in the Value-at-Risk (VaR) or Conditional VAR (CVaR) measures.
    \medskip

    \item "{\it In table 4, many of the bolded numbers are not different at a level of statistical significance. Ideally, the algorithm can be run more times for the camera ready to reduce the uncertainty about performance."}
    
    Table 4 reports MAE at each bin constructed by discretizing the game context. The differences between the estimated scoring chances and real scoring chances are averaged over all the state-action pairs in a bin. The difference is significant based on a wilcoxon test and results for all samples, but the difference might be less significant if we look at the averaged numbers. 
    \medskip
    % We will increase number of runs on the revised version.

    \item "{\it Why is the correlation with traditional metrics a good way of measuring success? The "success measures" are very simplistic features of the game so it could be that a better correlation with these measures is actually a signal that the algorithm is doing something naive rather than sophisticated."}
    
    We study the correlation to success measures because 1) Unlike the supervised learning task or the RL controlling task, the player (or agent) evaluation task has no ground-truth labels or rewards to maximize, so we use the correlation. 2) In the experiment, we study the correlation to all measures (including some penalty measures) instead of one. In this way, we can know whether these player evaluation metric can form a comprehensive evaluation to a player's overall performance. 
    \medskip
    
    \item "{\it Why do traditional metrics better correlate with risk-seeking versions of (smaller values of c)?"}
    
    We assume the reviewer is asking for an explanation of the results about the risk-sensitive experiment in Section "Scoring Chance Prediction Performance". In this experiment, we find that when c becomes smaller, RiGIM becomes risk-seeking, and thus achieves a higher correlation with success measures. Firstly, we want to clarify that the curve is not monotonically decreasing. The curve often reaches its maximum with a small $c$. This is because, in general, a risk-seeking metric assigns larger values to risk-seeking actions like shot. Compared to other actions, risk-seeking actions are more correlated to success measures like a goal. However, when $c=0$, the metric becomes overly risk-seeking and the correlation will drop.
    \medskip
    
    \item "{\it Will the post-hoc calibration techniques developed in this work also apply to the offline RL control setting? Might this be a better approach than constraining the actions that the agent can take?"}
    
    Our work is based on some settings in Offline RL. Although we solve an agent-evaluation task instead of a controlling task, we believe the approach of measuring aleatoric and epistemic risks can be adapted to Offline RL. With the risk measure, the offline RL agent can prevent state-action pairs with large uncertainty during testing.
    \medskip
    
    \item "{\it Wouldn't these actions have different expected values and not just be different in terms of risk-seeking? I don't understand why a defenseman would be lower variance. Or is that an emergent finding of this study?}"

    Yes, it is true that the expected values of shots should be larger, but we also observe that the variance of the shot distribution is larger than that of carry and pass. To better illustrate this point, {\bf we have added 5 visualizations of the distributions of shots, carry and pass in appendix C.3}. Shots are more risk-seeking, but defenseman performs shot less frequently, so they have a lower ranking based on the risk-seeking estimation.
    \medskip

    \item "{\it Does this reveal that their EV is just so high that they are included regardless of risk preferences? I feel that there is a real missed opportunity to explain what the metric is doing in terms that could be useful to a practitioner.}"

    Connor McDavid appears in our top-10 risk-averse ranking (Table C.4 in Appendix), but he is {\bf not} included in the risk-seeking one (Table C.3 in Appendix). Tyler Seguin, on the other hand, is highly ranked by both of our rankings, although his RiGIM values are significantly different (13.71 v.s., 1.78) and the rating has changed (6th v.s., 9th). Risk preference does influence evaluation, but this influence has not dominated the ranking. The practitioner can use our model to analyze a player's performance by observing how his or her rating is influenced by risk levels. 
    \medskip

    \item "{\it I think the missing explanation is that I'm having a hard time reasoning about what a risk-averse but highly successful action should look like. Everything that is positive seems to qualify as "risk-seeking" to some extent. Is there some way that this metric might lead to a more nuanced understanding of defensive behavior (which don't seem to have as strong traditional metrics associated with them).}"

    A general intuition we receive from our experiment and the sport experts is "stronger teams or players take more risks" (we introduce in our summary of update), but we believe the intuition must depend on the game context. Let's use the shots in Figure 1 as an example, where the shot (b) is more risk-seeking than the shot (a) (since the estimated value distribution of action (b) has larger uncertainty, please check the updated version of our paper). In general, shot (b) is preferred since its distribution has a mode on the high scoring chance (0.8). However, in some cases, when the game is tied and about to end, players might prefer (a) since they cannot afford the loss of next-goal scoring chance (which indicates their opponent will have higher chance of scoring the next goal, see Figure C.3 in Appendix).
    \medskip

    \item "{\it Why would it be biased? There is no reason to think that the conventional metrics represent a risk-neutral measure of play. If you tune the hyper-parameter on a validation set that is unlikely to introduce bias.}"

    We are aware of your concerns and will add the results after hyper-parameters fine-tuning (The experiments are still running on our machine, and we will update the results as soon as possible.) .\medskip
\end{itemize}

\section{Addressing the Comments from Reviewer tcWQ}


\begin{itemize}
    \item {\it "Section 4 is a technical section, that is missing an intuitive description of their method, and that is missing a high level explanation. Can the authors please add to their technical description a high level explanation of the problems of related work that is addressed by their method. What is different, and why does it work better?"}

    Section "Modelling the Uncertainty of Action Values" introduces a detailed implementation of the "Uncertainty-Aware RL framework", where we show the risk-sensitive player evaluation requests modeling both the epistemic and aleatoric uncertainty inherent to the environment dynamic. Ignoring any of these uncertainties will cause inaccurate estimation, which we show in the experiment (by comparing with GIM and Na-RiGIM). In Section 4, we introduce a distributional-RL model and a feature-space density estimator to estimate the aforementioned epistemic and aleatoric uncertainties. To the best of our knowledge, none of the previous RL works are based on the direct estimation of both uncertainties. Since estimating the epistemic and aleatoric uncertainty together is very challenging in practice, the technical details are included to demonstrate why our model (distributional RL + SP-CNF) is a proper uncertainty estimator from both an intuitive and theoretical perspectives. We have added the clarification to our revised version.
    \medskip

    \item {\it "Examples of where the explanations can be improved; In Section 6.1 the authors write: “If we remove SP-CNF or replace it with other uncertainty estimators, most correlations become weaker except for the correlations with the SHP and SHG measures.” Can you please explain or speculate why this is the case?"}

    This is because SHP and SHG rarely happen in a season (since scoring with fewer players on ice is difficult). Since SP-CNF is a density estimator, it assigns a small density to these rarely-occurring events. According to equation (5), the events with a small density ($p(\cdot|{z}_{E})$) will be filtered. This filtering is necessary since events with negligible probability are considered to have large epistemic uncertainty, but the filtering sometimes causes a loss of information. This is the main reason why RiGIM does not have a leading correlation with SHP and SHG. Capturing the correct values for these out-of-distribution events is generally difficult (check [Gal2016]). We have expanded the explanation in the revised version.\medskip

    [Gal2016] Gal, Yarin. "Uncertainty in deep learning." PhD thesis, 2016.

    \item {\it "Section 6, and Table 4 and 5 show correlations that are rather low, yet section 6.2 and section 6.3 fail to address this issue."}

    We have measured the correlations with both {\bf success} measures and {\bf penalty} measures, i.e., the correlations in the columns on the right-hand side of the dashed line (in Tables 1 and 2) should be as low as possible since the metrics refer to penalties.  In the terms of the scale of correlations, we study the correlation to {\bf all} measures (including some penalty measures) instead of one. Having perfect correlations or anti-correlations to all these measures is impossible since they measure different aspects of a player. We on the other hand study which player evaluation metric can better correlate with these measures and thus forms a comprehensive evaluation of a player's overall performance.  We have clarified it in the revised version.\medskip

    \item {\it "The authors write: “RiGIM(c) becomes risk-seeking, and thus achieves a higher correlation with success measures. However, the correlations drop when c approaches 0. This observation is consistent with the fact that an overly risk-seeking estimate cannot reflect the real contributions of players.” Why is that so, why can it not reflect the real contributions?"}

    This is because when c approaches 0, RiGIM will focus on the quantile level 1 (since 1-c=1, check the line after equation (5)), which corresponds to the largest value in the support of a distribution. In our case, this is the most optimistic estimation of the value that an action can achieve. For example, in the value distribution of shots, $Z^{1}(\cdot,shot)$ will be close to 1 most of the time, since the best outcome of a shot is scoring. However, in fact, only a few shots can turn into goals for both soccer and ice-hockey. The overly risk-seeking estimation can induce the mismatch between estimated values and game facts. We have expanded the explanation in the revised version.\medskip

    \item {\it "The authors may also consider adding an explicit problem statement and revising their contributions to address questions of the field..."}

     Our work involves interdisciplinary study from both sports analytics and Reinforcement Learning (RL). From the perspective of sports analytics, player evaluation is an important topic that has been studied by many previous works(see our related work Section 2). Assigning values to players' actions is a common approach for player evaluation, but none of the previous works has considered risk or uncertainty during evaluation. Our work extends the action-value approach by adding the dimension of risk to evaluation. This extension is {\bf fundamental} since sports games (especially team sports) have {\bf inherent risk and uncertainty}, which should not be ignored during evaluation. When it comes to RL, some recent works (i.e., offline RL) have studied the approach of adjusting action values according to uncertainty estimates, but these works often {\bf do not explicitly model the epistemic and aleatoric uncertainties} (in most cases, the estimation can not be disentangled into epistemic and aleatoric uncertainties, see [Mavrin2019]). Our work proposes a framework that enables this estimation. We have clarified it in the revised version.\medskip

[Mavrin2019] Borislav Mavrin, Hengshuai Yao, Linglong Kong, Kaiwen Wu, and Yaoliang Yu. Distributional reinforcement learning for efficient exploration. In International Conference on Machine Learning (ICML), volume 97, pages 4424–4434, 2019.\medskip

    \item {\it "The method is called RIGIM Distributional methods previously used in Atari and Mujoco are now used to evaluate real games."}

    Our method RIGIM is new and proposed for agent evaluation. It is novel and has not been applied to solve the control problems in Atari and Mujoco.\medskip

    \item {\it " What is the problem that is addressed?"}

    We explain the problem in the first paragraph of the introduction. The last sentence of this paragraph explains that the paper tackles the problem of player evaluation. To be more specific, we are considering a problem of assigning proper credits to players' actions by conditioning on a risk level. This is a fundamental challenge in sports analytics.\medskip

    \item {\it " How it builds on other work, how it compares to other work, what the strengths and weaknesses compared to other work are"}

    Our empirical evaluation follows an ablation design: We iteratively remove parts from RiGIM, and we show these simplifications degrade RiGIM to risk-neural or tabular-based baselines. This ablation study allow us to analyse the influence of each component in RiGIM, including the risk-sensitivity and uncertainty estimation models. The results in our experiment are presented by following the structure of the ablation study. We have expanded the explanation about experiments results, including the strengths and weaknesses compared to comparison methods in the revised version.\medskip
\end{itemize}

\end{document}